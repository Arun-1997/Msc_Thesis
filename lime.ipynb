{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd321a5-599d-4da3-b7e2-c7a4de2fde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.util import as_float\n",
    "\n",
    "# # import cython\n",
    "# import pyximport\n",
    "# pyximport.install(setup_args={\"script_args\" : [\"--verbose\"]})\n",
    "\n",
    "# from skimage.filters import gaussian\n",
    "# from skimage2.utils import _supported_float_type\n",
    "# from skimage.color import rgb2lab\n",
    "# from skimage.util import img_as_float\n",
    "# from skimage2._quickshift_cy import _quickshift_cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0313df-912e-4347-adfa-d3a2dd3b0d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 14:59:55.964435: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/lib/jvm/java-11-openjdk-amd64/lib/server:/opt/hadoop/lib/native:/usr/local/lib/R/lib:/usr/local/grass82/lib\n",
      "2023-03-17 14:59:55.964449: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-17 14:59:57.814930: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/lib/jvm/java-11-openjdk-amd64/lib/server:/opt/hadoop/lib/native:/usr/local/lib/R/lib:/usr/local/grass82/lib\n",
      "2023-03-17 14:59:57.814944: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-17 14:59:57.814957: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (adb88a00ea0a): /proc/driver/nvidia/version does not exist\n",
      "2023-03-17 14:59:57.815111: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import glob\n",
    "from rasterio.plot import reshape_as_image\n",
    "from tensorflow.keras import models\n",
    "\n",
    "from LimeImageExplainer2 import LimeImageExplainer2\n",
    "\n",
    "\n",
    "file = rasterio.open('Input/sentinel/patches_256/Iowa_July_1_31/test/Iowa_2021_july_1280-3072.tif')\n",
    "img = reshape_as_image(file.read())\n",
    "file.close()\n",
    "img_batch = np.expand_dims(img, axis=0)\n",
    "# model_id = \"aanaxs4g\" # With mask\n",
    "model_id = \"ezb3xkqf\" # No Mask\n",
    "model_path = glob.glob(\"wandb/\"+ \"*\"+model_id+\"*\" + \"/files/model-best.h5\")[0]\n",
    "\n",
    "# print(model_path)\n",
    "cnn_model = models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff8981-6866-4c70-846a-65e972cda737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 13)\n",
      "<class 'LimeImageExplainer2.LimeImageExplainer2'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert from object to float64.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m explainer \u001b[38;5;241m=\u001b[39m LimeImageExplainer2(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m explanation \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mexplain_instance(\n\u001b[1;32m      3\u001b[0m          img_batch,\n\u001b[1;32m      4\u001b[0m          cnn_model\u001b[38;5;241m.\u001b[39mpredict\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/MSC_Thesis/MSc_Thesis_2023/LimeImageExplainer2.py:122\u001b[0m, in \u001b[0;36mLimeImageExplainer2.explain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed, progress_bar)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m segmentation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# segmentation_fn = SegmentationAlgorithm('quickshift', kernel_size=4,\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m#                                         max_dist=200, ratio=0.2,\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m#                                         random_seed=random_seed)\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mprint\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 122\u001b[0m     segmentation_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquickshift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmax_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m segments \u001b[38;5;241m=\u001b[39m segmentation_fn\n\u001b[1;32m    125\u001b[0m fudged_image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/MSC_Thesis/MSc_Thesis_2023/LimeImageExplainer2.py:259\u001b[0m, in \u001b[0;36mLimeImageExplainer2.quickshift\u001b[0;34m(image1, ratio, kernel_size, max_dist, return_tree, sigma, convert2lab, random_seed, channel_axis)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(image1))\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# image = image[0]\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mimg_as_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m float_dtype \u001b[38;5;241m=\u001b[39m _supported_float_type(image\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    261\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mastype(float_dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/skimage/util/dtype.py:468\u001b[0m, in \u001b[0;36mimg_as_float\u001b[0;34m(image, force_copy)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimg_as_float\u001b[39m(image, force_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;124;03m\"\"\"Convert an image to floating point format.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m    This function is similar to `img_as_float64`, but will not convert\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m \n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloating\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_copy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/skimage/util/dtype.py:255\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(image, dtype, force_copy, uniform)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (dtype_in \u001b[38;5;129;01min\u001b[39;00m _supported_types \u001b[38;5;129;01mand\u001b[39;00m dtype_out \u001b[38;5;129;01min\u001b[39;00m _supported_types):\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot convert from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtypeobj_in\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    256\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtypeobj_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kind_in \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mui\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    259\u001b[0m     imin_in \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(dtype_in)\u001b[38;5;241m.\u001b[39mmin\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert from object to float64."
     ]
    }
   ],
   "source": [
    "explainer = LimeImageExplainer2(random_state=42)\n",
    "explanation = explainer.explain_instance(\n",
    "         img_batch,\n",
    "         cnn_model.predict\n",
    ")\n",
    "# plt.imshow(img_batch[10])\n",
    "# image, mask = explanation.get_image_and_mask(\n",
    "#          cnn_model.predict(\n",
    "#               img_batch).argmax(axis=1)[0],positive_only=True,hide_rest=False)\n",
    "# plt.imshow(mark_boundaries(image, mask))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
