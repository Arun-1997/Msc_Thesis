{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a10d0b2-93fa-4423-8880-ad8726cd475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.plot import reshape_as_image\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob,os,sys,cv2\n",
    "from datetime import datetime\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "training_path = \"Input/sentinel/test_data_from_drive/patches_all/normalised_train\"\n",
    "target_file_path = \"Input/Target/concat/target_yield.shp\"\n",
    "patch_dim = (256, 256, 13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "477e7a9d-1178-481d-b7ad-9010ca15bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 10\n",
    "lr = 1e-4\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = (y_true * y_pred).sum()\n",
    "        union = y_true.sum() + y_pred.sum() - intersection\n",
    "        x = (intersection + 1e-15) / (union + 1e-15)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e265cae-e649-4f37-82c5-db97379973a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "    # Conv2D then ReLU activation\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "    # Conv2D then ReLU activation\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "    return x\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "    f = double_conv_block(x, n_filters)\n",
    "    p = layers.MaxPool2D(2)(f)\n",
    "    p = layers.Dropout(0.3)(p)\n",
    "    return f, p\n",
    "\n",
    "def upsample_block(x, conv_features, n_filters):\n",
    "    # upsample\n",
    "    x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "    # concatenate\n",
    "    x = layers.concatenate([x, conv_features])\n",
    "    # dropout\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    # Conv2D twice with ReLU activation\n",
    "    x = double_conv_block(x, n_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b692c632-848f-4cb1-9b9d-a78154414fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Patches: 12411\n",
      "Any Null values?  False\n",
      "x shape :(12361, 256, 256, 12), y shape: (12361, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "def read_training():\n",
    "    training_file_list = glob.glob(os.path.join(training_path,\"*.tif\"))\n",
    "    target_gdf = gpd.read_file(target_file_path)\n",
    "    print(\"Total Number of Patches:\",len(training_file_list))\n",
    "    ignore_patch_list = list()\n",
    "    x = list()\n",
    "    y = list()\n",
    "    X_train = list()\n",
    "    X_test = list()\n",
    "    y_train = list()\n",
    "    y_test = list()\n",
    "    count = 0 \n",
    "    for file in training_file_list:\n",
    "\n",
    "        patch_src = rio.open(file)\n",
    "        f_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "        patch_src_read = reshape_as_image(patch_src.read()) ## Change the index here to add or remove the mask layer\n",
    "        # print(0)\n",
    "        if patch_src_read.shape != patch_dim:\n",
    "            ignore_patch_list.append(f_name)\n",
    "            # print(\"Patch Dimensions Mismatch, skipping patch : {}\".format(f_name))\n",
    "            continue\n",
    "\n",
    "        # print(1)\n",
    "        if np.isnan(patch_src_read).any():\n",
    "            # print(\"Has Nan values, skipping patch : {}\".format(f_name))\n",
    "            continue\n",
    "\n",
    "        # print(2)\n",
    "        query = target_gdf.query(f\"patch_name == '{f_name}'\")[\"ykg_by_e7\"]\n",
    "        if len(query) != 1:\n",
    "            # print(\"patch has no target value, skipping patch : {}\".format(f_name))\n",
    "            continue\n",
    "        # print(patch_src_read[:,:,0:12].shape)\n",
    "        # print(patch_src_read[:,:,12].shape)\n",
    "\n",
    "        x.append(patch_src_read[:,:,0:12])\n",
    "        y.append(patch_src_read[:,:,12])\n",
    "        # y.append(float(query))\n",
    "\n",
    "        patch_src.close()\n",
    "        # print(count)\n",
    "        count +=1\n",
    "        # if count > 100:\n",
    "        #     break\n",
    "\n",
    "    # self.y = self.scaler.fit_transform(np.array(self.y).reshape(-1, 1))\n",
    "    y = np.array(y)\n",
    "    y = np.expand_dims(y,-1)\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # x = (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "    print(\"Any Null values? \",np.isnan(x).any())\n",
    "    # print(self.y)\n",
    "    # self.x = np.nan_to_num(self.x, nan=0)# Check for different value for no data\n",
    "    print(f\"x shape :{x.shape}, y shape: {y.shape}\")\n",
    "    # print(np.nanmin(self.x),np.nanmax(self.x))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    #Also, split the training into train and val\n",
    "    # For testing, keep a part of the dataset as seperate (final month)\n",
    "\n",
    "X_train, X_test, y_train, y_test = read_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "babaf29d-46f0-4307-ba1c-89da3929effe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000019"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1409fceb-b1f6-4a30-aba8-4bf2b6760c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_LENGTH = info.splits[\"train\"].num_examples\n",
    "STEPS_PER_EPOCH = len(X_train) // BATCH_SIZE\n",
    "VAL_SUBSPLITS = 5\n",
    "# TEST_LENTH = info.splits[\"test\"].num_examples\n",
    "VALIDATION_STEPS = len(X_test) // BATCH_SIZE // VAL_SUBSPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfa471f6-a3ea-4630-b92b-f8cbb665de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet_model():\n",
    "    # inputs\n",
    "    inputs = layers.Input(shape=(256,256,12))\n",
    "\n",
    "    # encoder: contracting path - downsample\n",
    "    # 1 - downsample\n",
    "    f1, p1 = downsample_block(inputs, 64)\n",
    "    # 2 - downsample\n",
    "    f2, p2 = downsample_block(p1, 128)\n",
    "    # 3 - downsample\n",
    "    f3, p3 = downsample_block(p2, 256)\n",
    "    # 4 - downsample\n",
    "    f4, p4 = downsample_block(p3, 512)\n",
    "\n",
    "    # 5 - bottleneck\n",
    "    bottleneck = double_conv_block(p4, 1024)\n",
    "    \n",
    "    # flat = layers.Flatten()\n",
    "    # model.add(layers.Dense(64, activation='relu')) # Add another dense layer\n",
    "    # model.add(Dropout(0.5))\n",
    "    # model.add(layers.Dense(32, activation='relu'))\n",
    "    # model.add(layers.Dense(16, activation='relu'))\n",
    "    # model.add(layers.Dense(8, activation='relu'))\n",
    "    # model.add(layers.Dense(4, activation='relu'))\n",
    "    # model.add(layers.Dense(1,activation='linear'))\n",
    "    \n",
    "    # decoder: expanding path - upsample\n",
    "    # 6 - upsample\n",
    "    u6 = upsample_block(bottleneck, f4, 512)\n",
    "    # 7 - upsample\n",
    "    u7 = upsample_block(u6, f3, 256)\n",
    "    # 8 - upsample\n",
    "    u8 = upsample_block(u7, f2, 128)\n",
    "    # 9 - upsample\n",
    "    u9 = upsample_block(u8, f1, 64)\n",
    "\n",
    "    # outputs\n",
    "    # outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u9)\n",
    "\n",
    "    # unet model with Keras Functional API\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "\n",
    "    return unet_model\n",
    "\n",
    "\n",
    "unet_model = build_unet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "994e60ef-cd77-4291-b340-e34c4fcd587d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7efc5429dcd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b02d7a5b-7cc8-4b2f-8ab0-b256d594028d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
      "                                2)]                                                               \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 256, 256, 64  6976        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_38[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 128, 128, 64  0          ['conv2d_39[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 128, 128, 64  0           ['max_pooling2d_8[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 128, 128, 12  73856       ['dropout_16[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_40[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_41[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 64, 64, 128)  0           ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 64, 64, 256)  295168      ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_42[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_43[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 32, 32, 256)  0           ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 32, 32, 512)  1180160     ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_44[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 16, 16, 512)  0          ['conv2d_45[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 16, 16, 512)  0           ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 16, 16, 1024  4719616     ['dropout_19[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_46[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 32, 32, 512)  4719104    ['conv2d_47[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 32, 32, 1024  0           ['conv2d_transpose_8[0][0]',     \n",
      "                                )                                 'conv2d_45[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 32, 32, 1024  0           ['concatenate_8[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 32, 32, 512)  4719104     ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_48[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 64, 64, 256)  1179904    ['conv2d_49[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_9[0][0]',     \n",
      "                                                                  'conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 64, 64, 512)  0           ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 64, 64, 256)  1179904     ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_50[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 128, 128, 12  295040     ['conv2d_51[0][0]']              \n",
      " nspose)                        8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_transpose_10[0][0]',    \n",
      "                                6)                                'conv2d_41[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 128, 128, 25  0           ['concatenate_10[0][0]']         \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 128, 128, 12  295040      ['dropout_22[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_52[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 256, 256, 64  73792      ['conv2d_53[0][0]']              \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_transpose_11[0][0]',    \n",
      "                                8)                                'conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 256, 256, 12  0           ['concatenate_11[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 256, 256, 64  73792       ['dropout_23[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_54[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 256, 256, 1)  65          ['conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34,518,529\n",
      "Trainable params: 34,518,529\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1b90660-8f92-4792-aa81-2cf736025493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 15:44:40.663568: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29160898560 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "def tf_parse(x,y):\n",
    "    def f(x, y):\n",
    "        return x, y\n",
    "    images, masks = tf.numpy_function(f, [x, y], [tf.float32, tf.float32])\n",
    "    images.set_shape([256, 256, 12])\n",
    "    masks.set_shape([256, 256, 1])\n",
    "    return images, masks\n",
    "\n",
    "\n",
    "def tf_dataset(x,y,batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    # break\n",
    "    return dataset\n",
    "\n",
    "train_dataset = tf_dataset(X_train,y_train,batch=BATCH_SIZE)\n",
    "validation_dataset = tf_dataset(X_test,y_test,batch=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60a7c20c-1a73-4610-9197-d069f47018d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,j in train_dataset:\n",
    "#     i = i[0].numpy()\n",
    "#     j = j[0].numpy()\n",
    "#     j = np.squeeze(j,axis=-1)\n",
    "#     print(i.shape,j.shape)\n",
    "#     i=i*255\n",
    "#     j = j*255.0\n",
    "#     cv2.imwrite(\"img.png\",i[:,:,3:6])\n",
    "    \n",
    "#     cv2.imwrite(\"mask.png\",j)\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ecf4566-86e3-40a7-8840-92dd6d877f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = [\"acc\",tf.keras.metrics.Recall(), tf.keras.metrics.Precision(),tf.keras.metrics.BinaryIoU()]\n",
    "\n",
    "metrics = [tf.keras.metrics.BinaryIoU(target_class_ids = (0, 1),\n",
    "                            threshold=0.5,\n",
    "                            name=None,\n",
    "                            dtype=None), \n",
    "          tf.keras.metrics.BinaryAccuracy(\n",
    "                            name='binary_accuracy', dtype=None, threshold=0.5\n",
    "                        )]\n",
    "\n",
    "unet_model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=metrics)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"unet_multi_output/model_BSize_\"+str(BATCH_SIZE)+\"_NEpochs_\"+str(NUM_EPOCHS)+\"_\"+str(datetime.now())+\".h5\"),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2),\n",
    "    CSVLogger(\"unet_multi_output/data_BSize_\"+str(BATCH_SIZE)+\"_NEpochs_\"+str(NUM_EPOCHS)+\"_\"+str(datetime.now())+\".csv\"),\n",
    "    # TensorBoard(),\n",
    "    EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f53b16cd-5485-4ff4-be10-bd6d9db14ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 9448s 256s/step - loss: 0.5826 - binary_io_u_4: 0.3975 - binary_accuracy: 0.7483 - val_loss: 0.5311 - val_binary_io_u_4: 0.3905 - val_binary_accuracy: 0.7807 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 8965s 242s/step - loss: 0.5178 - binary_io_u_4: 0.3922 - binary_accuracy: 0.7801 - val_loss: 0.4961 - val_binary_io_u_4: 0.4478 - val_binary_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 8539s 231s/step - loss: 0.4771 - binary_io_u_4: 0.4349 - binary_accuracy: 0.7870 - val_loss: 0.5049 - val_binary_io_u_4: 0.5461 - val_binary_accuracy: 0.7728 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 8494s 230s/step - loss: 0.4463 - binary_io_u_4: 0.5043 - binary_accuracy: 0.8053 - val_loss: 0.4844 - val_binary_io_u_4: 0.5496 - val_binary_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 8447s 229s/step - loss: 0.4289 - binary_io_u_4: 0.5438 - binary_accuracy: 0.8162 - val_loss: 0.4600 - val_binary_io_u_4: 0.5691 - val_binary_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 8406s 228s/step - loss: 0.4128 - binary_io_u_4: 0.5683 - binary_accuracy: 0.8243 - val_loss: 0.4193 - val_binary_io_u_4: 0.5961 - val_binary_accuracy: 0.8128 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 8472s 229s/step - loss: 0.4027 - binary_io_u_4: 0.5797 - binary_accuracy: 0.8291 - val_loss: 0.3944 - val_binary_io_u_4: 0.6000 - val_binary_accuracy: 0.8320 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 8472s 229s/step - loss: 0.4007 - binary_io_u_4: 0.5818 - binary_accuracy: 0.8301 - val_loss: 0.3949 - val_binary_io_u_4: 0.6144 - val_binary_accuracy: 0.8306 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 8542s 231s/step - loss: 0.3929 - binary_io_u_4: 0.5908 - binary_accuracy: 0.8335 - val_loss: 0.3845 - val_binary_io_u_4: 0.6148 - val_binary_accuracy: 0.8372 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 8499s 230s/step - loss: 0.3885 - binary_io_u_4: 0.5953 - binary_accuracy: 0.8354 - val_loss: 0.3823 - val_binary_io_u_4: 0.6062 - val_binary_accuracy: 0.8403 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model_history = unet_model.fit(train_dataset,\n",
    "                              validation_data = validation_dataset,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              callbacks=callbacks)\n",
    "                              # steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                                 # validation_steps=VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f365d29-95e5-4936-9170-94f9b31b3c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "if dataset:\n",
    "for image, mask in dataset.take(num):\n",
    "pred_mask = unet_model.predict(image)\n",
    "display([image[0], mask[0], create_mask(pred_mask)])\n",
    "else:\n",
    "display([sample_image, sample_mask,\n",
    "    create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n",
    "count = 0\n",
    "for i in test_batches:\n",
    "   count +=1\n",
    "print(\"number of batches:\", count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
